{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Practices for Using Runners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: todd-ai 0.4.0\n",
      "Uninstalling todd-ai-0.4.0:\n",
      "  Successfully uninstalled todd-ai-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Processing /Users/bytedance/Developer/todd\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: einops in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from todd-ai==0.4.0) (0.6.1)\n",
      "Requirement already satisfied: lmdb in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from todd-ai==0.4.0) (1.4.1)\n",
      "Requirement already satisfied: opencv-python in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from todd-ai==0.4.0) (4.7.0.72)\n",
      "Requirement already satisfied: pandas in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from todd-ai==0.4.0) (2.0.1)\n",
      "Requirement already satisfied: python-pptx in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from todd-ai==0.4.0) (0.6.21)\n",
      "Requirement already satisfied: tensorboard in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from todd-ai==0.4.0) (2.13.0)\n",
      "Requirement already satisfied: timm in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from todd-ai==0.4.0) (0.9.2)\n",
      "Requirement already satisfied: toml in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from todd-ai==0.4.0) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from todd-ai==0.4.0) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from todd-ai==0.4.0) (4.5.0)\n",
      "Requirement already satisfied: yapf in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from todd-ai==0.4.0) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from opencv-python->todd-ai==0.4.0) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from pandas->todd-ai==0.4.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from pandas->todd-ai==0.4.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from pandas->todd-ai==0.4.0) (2023.3)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from python-pptx->todd-ai==0.4.0) (4.9.2)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from python-pptx->todd-ai==0.4.0) (9.5.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from python-pptx->todd-ai==0.4.0) (3.1.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from tensorboard->todd-ai==0.4.0) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from tensorboard->todd-ai==0.4.0) (1.54.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from tensorboard->todd-ai==0.4.0) (2.18.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from tensorboard->todd-ai==0.4.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from tensorboard->todd-ai==0.4.0) (3.4.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from tensorboard->todd-ai==0.4.0) (4.23.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from tensorboard->todd-ai==0.4.0) (2.30.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from tensorboard->todd-ai==0.4.0) (67.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from tensorboard->todd-ai==0.4.0) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from tensorboard->todd-ai==0.4.0) (2.3.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from tensorboard->todd-ai==0.4.0) (0.40.0)\n",
      "Requirement already satisfied: torch>=1.7 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from timm->todd-ai==0.4.0) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from timm->todd-ai==0.4.0) (0.15.2)\n",
      "Requirement already satisfied: pyyaml in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from timm->todd-ai==0.4.0) (6.0)\n",
      "Requirement already satisfied: huggingface-hub in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from timm->todd-ai==0.4.0) (0.14.1)\n",
      "Requirement already satisfied: safetensors in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from timm->todd-ai==0.4.0) (0.3.1)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from yapf->todd-ai==0.4.0) (2.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard->todd-ai==0.4.0) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard->todd-ai==0.4.0) (0.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard->todd-ai==0.4.0) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard->todd-ai==0.4.0) (1.26.15)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard->todd-ai==0.4.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->todd-ai==0.4.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard->todd-ai==0.4.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard->todd-ai==0.4.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard->todd-ai==0.4.0) (2023.5.7)\n",
      "Requirement already satisfied: filelock in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from torch>=1.7->timm->todd-ai==0.4.0) (3.12.0)\n",
      "Requirement already satisfied: sympy in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from torch>=1.7->timm->todd-ai==0.4.0) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from torch>=1.7->timm->todd-ai==0.4.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from torch>=1.7->timm->todd-ai==0.4.0) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard->todd-ai==0.4.0) (2.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from huggingface-hub->timm->todd-ai==0.4.0) (2023.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from huggingface-hub->timm->todd-ai==0.4.0) (23.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->todd-ai==0.4.0) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->todd-ai==0.4.0) (3.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages (from sympy->torch>=1.7->timm->todd-ai==0.4.0) (1.3.0)\n",
      "Building wheels for collected packages: todd-ai\n",
      "  Building wheel for todd-ai (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for todd-ai: filename=todd_ai-0.4.0-py3-none-any.whl size=109857 sha256=3e4dbb39f9adbfd52fc9d2bd67d3dbeb0bdaf1d4112c950025805601046ffe74\n",
      "  Stored in directory: /private/var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/pip-ephem-wheel-cache-2hfcgmpx/wheels/15/ef/5a/9fc12e257ce5cef16b333a2ed6c992ff9cbcc9167f7199e6ac\n",
      "Successfully built todd-ai\n",
      "Installing collected packages: todd-ai\n",
      "Successfully installed todd-ai-0.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y todd_ai\n",
    "%pip install .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-28 20:13:39,892 36766:140704306648640][patches.py:7 todd <module>] INFO: `ipdb` is installed. Using it for debugging.\n",
      "/Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tempfile\n",
    "from pprint import pprint\n",
    "from typing import Any, NoReturn, TypedDict\n",
    "\n",
    "import todd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "Memo = dict[str, Any]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@todd.ModelRegistry.register()\n",
    "class RunnerModel(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self._weight = torch.nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    @property\n",
    "    def weight(self) -> torch.nn.Parameter:\n",
    "        return self._weight\n",
    "\n",
    "    def _forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x * self._weight\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        runner: todd.runners.BaseRunner,\n",
    "        batch,\n",
    "        memo: Memo,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ) -> Memo:\n",
    "        log: dict[str, Any] | None = memo.get('log')\n",
    "        y = self._forward(batch['x'])\n",
    "        loss = F.l1_loss(y, batch['y'])\n",
    "        memo['loss'] = loss\n",
    "        if log is not None:\n",
    "            log['batch'] = str(batch)\n",
    "            log['weight'] = f'{self._weight.item():.3f}'\n",
    "            log['loss'] = f'{loss:.3f}'\n",
    "        return memo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample(TypedDict):\n",
    "    x: int\n",
    "    y: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@todd.DatasetRegistry.register()\n",
    "class RunnerDataset(torch.utils.data.Dataset[int]):\n",
    "\n",
    "    def __init__(self, n: int) -> None:\n",
    "        self._data = list(range(1, n + 1))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Sample:\n",
    "        x = self._data[index]\n",
    "        return Sample(x=x, y=x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch(TypedDict):\n",
    "    x: torch.Tensor\n",
    "    y: torch.Tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator_demo = todd.Config(\n",
    "    type='Validator',\n",
    "    name='validator',\n",
    "    dataloader=dict(batch_size=1, dataset=dict(type='RunnerDataset', n=20)),\n",
    "    strategy=dict(type='BaseStrategy', model=dict(type='RunnerModel')),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m[2023-08-28 20:13:42,082 36766:140704306648640][base.py:54 todd.Validator.validator __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36m/var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmphjs1zw17\u001b[0m\n",
      "└── \u001b[1;36mvalidator\u001b[0m\n",
      "\n",
      "2 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.Validator = todd.RunnerRegistry.build(\n",
    "        validator_demo, \n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.run()\n",
    "    \n",
    "    !echo\n",
    "    !tree $work_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator_demo.callbacks = dict(type='LogCallback', interval=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m[2023-08-28 20:13:42,415 36766:140704306648640][base.py:54 todd.Validator.validator __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:42,419 36766:140704306648640][log.py:84 todd.Validator.validator after_run_iter] INFO: Iter [5/20] ETA 0:00:00 batch={'x': tensor([5]), 'y': tensor([10])} weight=0.000 loss=10.000\n",
      "[2023-08-28 20:13:42,421 36766:140704306648640][log.py:84 todd.Validator.validator after_run_iter] INFO: Iter [10/20] ETA 0:00:00 batch={'x': tensor([10]), 'y': tensor([20])} weight=0.000 loss=20.000\n",
      "[2023-08-28 20:13:42,424 36766:140704306648640][log.py:84 todd.Validator.validator after_run_iter] INFO: Iter [15/20] ETA 0:00:00 batch={'x': tensor([15]), 'y': tensor([30])} weight=0.000 loss=30.000\n",
      "[2023-08-28 20:13:42,426 36766:140704306648640][log.py:84 todd.Validator.validator after_run_iter] INFO: Iter [20/20] ETA 0:00:00 batch={'x': tensor([20]), 'y': tensor([40])} weight=0.000 loss=40.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36m/var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp4cb3xd0q\u001b[0m\n",
      "└── \u001b[1;36mvalidator\u001b[0m\n",
      "\n",
      "2 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.Validator = todd.RunnerRegistry.build(\n",
    "        validator_demo, \n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.run()\n",
    "    \n",
    "    !echo\n",
    "    !tree $work_dirs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_demo = validator_demo.copy()\n",
    "trainer_demo.pop('type')\n",
    "trainer_demo.dataloader = todd.Config(\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    dataset=dict(type='RunnerDataset', n=67),\n",
    ")\n",
    "trainer_demo.optimizer = todd.Config(type='SGD', lr=0.005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_based_trainer_demo = trainer_demo.copy()\n",
    "iter_based_trainer_demo.type = 'IterBasedTrainer'\n",
    "iter_based_trainer_demo.name = 'iter_based_trainer'\n",
    "iter_based_trainer_demo.iters = 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m[2023-08-28 20:13:42,726 36766:140704306648640][base.py:54 todd.IterBasedTrainer.iter_based_trainer __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:42,729 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [5/53] ETA 0:00:00 batch={'x': tensor([44,  8]), 'y': tensor([88, 16])} weight=0.000 loss=52.000\n",
      "[2023-08-28 20:13:42,732 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [10/53] ETA 0:00:00 batch={'x': tensor([ 6, 53]), 'y': tensor([ 12, 106])} weight=0.000 loss=59.000\n",
      "[2023-08-28 20:13:42,734 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [15/53] ETA 0:00:00 batch={'x': tensor([18, 48]), 'y': tensor([36, 96])} weight=0.000 loss=66.000\n",
      "[2023-08-28 20:13:42,736 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [20/53] ETA 0:00:00 batch={'x': tensor([22, 23]), 'y': tensor([44, 46])} weight=0.000 loss=45.000\n",
      "[2023-08-28 20:13:42,739 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [25/53] ETA 0:00:00 batch={'x': tensor([ 2, 64]), 'y': tensor([  4, 128])} weight=0.000 loss=66.000\n",
      "[2023-08-28 20:13:42,741 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [30/53] ETA 0:00:00 batch={'x': tensor([58, 20]), 'y': tensor([116,  40])} weight=0.000 loss=78.000\n",
      "[2023-08-28 20:13:42,744 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [35/53] ETA 0:00:00 batch={'x': tensor([38, 29]), 'y': tensor([76, 58])} weight=0.000 loss=67.000\n",
      "[2023-08-28 20:13:42,745 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [40/53] ETA 0:00:00 batch={'x': tensor([51, 11]), 'y': tensor([102,  22])} weight=0.000 loss=62.000\n",
      "[2023-08-28 20:13:42,747 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [45/53] ETA 0:00:00 batch={'x': tensor([41, 24]), 'y': tensor([82, 48])} weight=0.000 loss=65.000\n",
      "[2023-08-28 20:13:42,749 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [50/53] ETA 0:00:00 batch={'x': tensor([ 3, 60]), 'y': tensor([  6, 120])} weight=0.000 loss=63.000\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.IterBasedTrainer = todd.RunnerRegistry.build(\n",
    "        iter_based_trainer_demo,\n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_based_trainer_demo = trainer_demo.copy()\n",
    "epoch_based_trainer_demo.type = 'EpochBasedTrainer'\n",
    "epoch_based_trainer_demo.name = 'epoch_based_trainer'\n",
    "epoch_based_trainer_demo.epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m[2023-08-28 20:13:42,768 36766:140704306648640][base.py:54 todd.EpochBasedTrainer.epoch_based_trainer __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:42,768 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [1/3]\n",
      "[2023-08-28 20:13:42,772 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [5/102] ETA 0:00:00 batch={'x': tensor([61, 17]), 'y': tensor([122,  34])} weight=0.000 loss=78.000\n",
      "[2023-08-28 20:13:42,774 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [10/102] ETA 0:00:00 batch={'x': tensor([16, 25]), 'y': tensor([32, 50])} weight=0.000 loss=41.000\n",
      "[2023-08-28 20:13:42,777 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [15/102] ETA 0:00:00 batch={'x': tensor([10, 21]), 'y': tensor([20, 42])} weight=0.000 loss=31.000\n",
      "[2023-08-28 20:13:42,779 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [20/102] ETA 0:00:00 batch={'x': tensor([52, 12]), 'y': tensor([104,  24])} weight=0.000 loss=64.000\n",
      "[2023-08-28 20:13:42,781 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [25/102] ETA 0:00:00 batch={'x': tensor([50, 27]), 'y': tensor([100,  54])} weight=0.000 loss=77.000\n",
      "[2023-08-28 20:13:42,783 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [30/102] ETA 0:00:00 batch={'x': tensor([ 4, 41]), 'y': tensor([ 8, 82])} weight=0.000 loss=45.000\n",
      "[2023-08-28 20:13:42,785 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [2/3]\n",
      "[2023-08-28 20:13:42,787 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [35/102] ETA 0:00:00 batch={'x': tensor([49,  1]), 'y': tensor([98,  2])} weight=0.000 loss=50.000\n",
      "[2023-08-28 20:13:42,789 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [40/102] ETA 0:00:00 batch={'x': tensor([ 6, 35]), 'y': tensor([12, 70])} weight=0.000 loss=41.000\n",
      "[2023-08-28 20:13:42,791 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [45/102] ETA 0:00:00 batch={'x': tensor([13, 29]), 'y': tensor([26, 58])} weight=0.000 loss=42.000\n",
      "[2023-08-28 20:13:42,793 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [50/102] ETA 0:00:00 batch={'x': tensor([30, 12]), 'y': tensor([60, 24])} weight=0.000 loss=42.000\n",
      "[2023-08-28 20:13:42,795 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [55/102] ETA 0:00:00 batch={'x': tensor([15, 54]), 'y': tensor([ 30, 108])} weight=0.000 loss=69.000\n",
      "[2023-08-28 20:13:42,798 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [60/102] ETA 0:00:00 batch={'x': tensor([47, 34]), 'y': tensor([94, 68])} weight=0.000 loss=81.000\n",
      "[2023-08-28 20:13:42,799 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [65/102] ETA 0:00:00 batch={'x': tensor([53, 42]), 'y': tensor([106,  84])} weight=0.000 loss=95.000\n",
      "[2023-08-28 20:13:42,801 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [3/3]\n",
      "[2023-08-28 20:13:42,803 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [70/102] ETA 0:00:00 batch={'x': tensor([14, 53]), 'y': tensor([ 28, 106])} weight=0.000 loss=67.000\n",
      "[2023-08-28 20:13:42,805 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [75/102] ETA 0:00:00 batch={'x': tensor([29, 11]), 'y': tensor([58, 22])} weight=0.000 loss=40.000\n",
      "[2023-08-28 20:13:42,808 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [80/102] ETA 0:00:00 batch={'x': tensor([ 6, 50]), 'y': tensor([ 12, 100])} weight=0.000 loss=56.000\n",
      "[2023-08-28 20:13:42,810 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [85/102] ETA 0:00:00 batch={'x': tensor([24, 27]), 'y': tensor([48, 54])} weight=0.000 loss=51.000\n",
      "[2023-08-28 20:13:42,812 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [90/102] ETA 0:00:00 batch={'x': tensor([33, 37]), 'y': tensor([66, 74])} weight=0.000 loss=70.000\n",
      "[2023-08-28 20:13:42,814 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [95/102] ETA 0:00:00 batch={'x': tensor([43, 65]), 'y': tensor([ 86, 130])} weight=0.000 loss=108.000\n",
      "[2023-08-28 20:13:42,816 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [100/102] ETA 0:00:00 batch={'x': tensor([35, 54]), 'y': tensor([ 70, 108])} weight=0.000 loss=89.000\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.EpochBasedTrainer = todd.RunnerRegistry.build(\n",
    "        epoch_based_trainer_demo,\n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_callback_demo = validator_demo.copy()\n",
    "log_callback = log_callback_demo.callbacks\n",
    "log_callback.collect_env = todd.Config(verbose=False)\n",
    "log_callback.with_file_handler = True\n",
    "log_callback_demo.callbacks = [log_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-28 20:13:42,999 36766:140704306648640][log.py:50 todd.Validator.validator init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "\u001b[2m[2023-08-28 20:13:43,001 36766:140704306648640][base.py:54 todd.Validator.validator __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:43,005 36766:140704306648640][log.py:84 todd.Validator.validator after_run_iter] INFO: Iter [5/20] ETA 0:00:00 batch={'x': tensor([5]), 'y': tensor([10])} weight=0.000 loss=10.000\n",
      "[2023-08-28 20:13:43,007 36766:140704306648640][log.py:84 todd.Validator.validator after_run_iter] INFO: Iter [10/20] ETA 0:00:00 batch={'x': tensor([10]), 'y': tensor([20])} weight=0.000 loss=20.000\n",
      "[2023-08-28 20:13:43,009 36766:140704306648640][log.py:84 todd.Validator.validator after_run_iter] INFO: Iter [15/20] ETA 0:00:00 batch={'x': tensor([15]), 'y': tensor([30])} weight=0.000 loss=30.000\n",
      "[2023-08-28 20:13:43,012 36766:140704306648640][log.py:84 todd.Validator.validator after_run_iter] INFO: Iter [20/20] ETA 0:00:00 batch={'x': tensor([20]), 'y': tensor([40])} weight=0.000 loss=40.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36m/var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmpsdjb1c5d\u001b[0m\n",
      "└── \u001b[1;36mvalidator\u001b[0m\n",
      "    └── 2023-08-28T20-13-42_838268-08-00.log\n",
      "\n",
      "2 directories, 1 file\n",
      "\n",
      "[2023-08-28 20:13:42,999 36766:140704306648640][log.py:50 todd.Validator.validator init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "[2023-08-28 20:13:43,001 36766:140704306648640][base.py:54 todd.Validator.validator __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\n",
      "[2023-08-28 20:13:43,005 36766:140704306648640][log.py:84 todd.Validator.validator after_run_iter] INFO: Iter [5/20] ETA 0:00:00 batch={'x': tensor([5]), 'y': tensor([10])} weight=0.000 loss=10.000\n",
      "[2023-08-28 20:13:43,007 36766:140704306648640][log.py:84 todd.Validator.validator after_run_iter] INFO: Iter [10/20] ETA 0:00:00 batch={'x': tensor([10]), 'y': tensor([20])} weight=0.000 loss=20.000\n",
      "[2023-08-28 20:13:43,009 36766:140704306648640][log.py:84 todd.Validator.validator after_run_iter] INFO: Iter [15/20] ETA 0:00:00 batch={'x': tensor([15]), 'y': tensor([30])} weight=0.000 loss=30.000\n",
      "[2023-08-28 20:13:43,012 36766:140704306648640][log.py:84 todd.Validator.validator after_run_iter] INFO: Iter [20/20] ETA 0:00:00 batch={'x': tensor([20]), 'y': tensor([40])} weight=0.000 loss=40.000\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.Validator = todd.RunnerRegistry.build(\n",
    "        log_callback_demo, \n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.run()\n",
    "\n",
    "    !echo\n",
    "    !tree {work_dirs}\n",
    "    !echo\n",
    "    !cat {work_dirs}/validator/*.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_callback_demo = iter_based_trainer_demo.copy()\n",
    "optimize_callback = todd.Config(type='OptimizeCallback')\n",
    "optimize_callback_demo.callbacks = [optimize_callback, log_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-28 20:13:43,661 36766:140704306648640][log.py:50 todd.IterBasedTrainer.iter_based_trainer init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "\u001b[2m[2023-08-28 20:13:43,663 36766:140704306648640][base.py:54 todd.IterBasedTrainer.iter_based_trainer __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:43,668 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [5/53] ETA 0:00:00 batch={'x': tensor([33, 42]), 'y': tensor([66, 84])} weight=0.765 loss=46.312\n",
      "[2023-08-28 20:13:43,672 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [10/53] ETA 0:00:00 batch={'x': tensor([16, 29]), 'y': tensor([32, 58])} weight=1.455 loss=12.262\n",
      "[2023-08-28 20:13:43,675 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [15/53] ETA 0:00:00 batch={'x': tensor([ 6, 27]), 'y': tensor([12, 54])} weight=1.815 loss=3.053\n",
      "[2023-08-28 20:13:43,678 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [20/53] ETA 0:00:00 batch={'x': tensor([40, 55]), 'y': tensor([ 80, 110])} weight=1.912 loss=4.156\n",
      "[2023-08-28 20:13:43,682 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [25/53] ETA 0:00:00 batch={'x': tensor([ 2, 64]), 'y': tensor([  4, 128])} weight=2.095 loss=3.135\n",
      "[2023-08-28 20:13:43,685 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [30/53] ETA 0:00:00 batch={'x': tensor([22,  1]), 'y': tensor([44,  2])} weight=1.882 loss=1.351\n",
      "[2023-08-28 20:13:43,688 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [35/53] ETA 0:00:00 batch={'x': tensor([50,  4]), 'y': tensor([100,   8])} weight=1.977 loss=0.608\n",
      "[2023-08-28 20:13:43,691 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [40/53] ETA 0:00:00 batch={'x': tensor([18, 28]), 'y': tensor([36, 56])} weight=2.070 loss=1.610\n",
      "[2023-08-28 20:13:43,694 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [45/53] ETA 0:00:00 batch={'x': tensor([57, 39]), 'y': tensor([114,  78])} weight=2.000 loss=0.000\n",
      "[2023-08-28 20:13:43,696 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [50/53] ETA 0:00:00 batch={'x': tensor([14, 37]), 'y': tensor([28, 74])} weight=1.865 loss=3.443\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.IterBasedTrainer = todd.RunnerRegistry.build(\n",
    "        optimize_callback_demo,\n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule_callback_demo = iter_based_trainer_demo.copy()\n",
    "lr_schedule_callback = todd.Config(\n",
    "    type='LRScheduleCallback',\n",
    "    lr_scheduler=dict(type='LinearLR', total_iters=10),\n",
    ")\n",
    "lr_schedule_callback_demo.callbacks = [\n",
    "    optimize_callback,\n",
    "    lr_schedule_callback,\n",
    "    log_callback,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-28 20:13:43,810 36766:140704306648640][log.py:50 todd.IterBasedTrainer.iter_based_trainer init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "\u001b[2m[2023-08-28 20:13:43,812 36766:140704306648640][base.py:54 todd.IterBasedTrainer.iter_based_trainer __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:43,817 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [5/53] ETA 0:00:00 batch={'x': tensor([51, 62]), 'y': tensor([102, 124])} weight=0.311 loss=95.438 lr=['3.333e-03']\n",
      "[2023-08-28 20:13:43,821 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [10/53] ETA 0:00:00 batch={'x': tensor([14, 12]), 'y': tensor([28, 24])} weight=0.883 loss=14.523 lr=['5.000e-03']\n",
      "[2023-08-28 20:13:43,825 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [15/53] ETA 0:00:00 batch={'x': tensor([55, 18]), 'y': tensor([110,  36])} weight=1.643 loss=13.012 lr=['5.000e-03']\n",
      "[2023-08-28 20:13:43,828 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [20/53] ETA 0:00:00 batch={'x': tensor([47, 30]), 'y': tensor([94, 60])} weight=2.011 loss=0.423 lr=['5.000e-03']\n",
      "[2023-08-28 20:13:43,832 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [25/53] ETA 0:00:00 batch={'x': tensor([44, 36]), 'y': tensor([88, 72])} weight=2.156 loss=6.240 lr=['5.000e-03']\n",
      "[2023-08-28 20:13:43,835 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [30/53] ETA 0:00:00 batch={'x': tensor([66, 39]), 'y': tensor([132,  78])} weight=2.096 loss=5.040 lr=['5.000e-03']\n",
      "[2023-08-28 20:13:43,838 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [35/53] ETA 0:00:00 batch={'x': tensor([15, 16]), 'y': tensor([30, 32])} weight=2.161 loss=2.495 lr=['5.000e-03']\n",
      "[2023-08-28 20:13:43,841 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [40/53] ETA 0:00:00 batch={'x': tensor([ 2, 13]), 'y': tensor([ 4, 26])} weight=1.748 loss=1.886 lr=['5.000e-03']\n",
      "[2023-08-28 20:13:43,844 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [45/53] ETA 0:00:00 batch={'x': tensor([42, 20]), 'y': tensor([84, 40])} weight=1.988 loss=0.357 lr=['5.000e-03']\n",
      "[2023-08-28 20:13:43,847 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [50/53] ETA 0:00:00 batch={'x': tensor([ 8, 19]), 'y': tensor([16, 38])} weight=2.181 loss=2.443 lr=['5.000e-03']\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.IterBasedTrainer = todd.RunnerRegistry.build(\n",
    "        lr_schedule_callback_demo,\n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule_by_epoch_callback_demo = epoch_based_trainer_demo.copy()\n",
    "lr_schedule_by_epoch_callback = lr_schedule_callback.copy()\n",
    "lr_schedule_by_epoch_callback.by_epoch = True\n",
    "lr_schedule_by_epoch_callback_demo.callbacks = [\n",
    "    optimize_callback,\n",
    "    lr_schedule_by_epoch_callback,\n",
    "    log_callback,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-28 20:13:43,994 36766:140704306648640][log.py:50 todd.EpochBasedTrainer.epoch_based_trainer init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "\u001b[2m[2023-08-28 20:13:43,996 36766:140704306648640][base.py:54 todd.EpochBasedTrainer.epoch_based_trainer __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:43,997 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [1/3]\n",
      "[2023-08-28 20:13:44,002 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [5/102] ETA 0:00:00 batch={'x': tensor([45, 22]), 'y': tensor([90, 44])} weight=0.236 loss=59.100 lr=['1.667e-03']\n",
      "[2023-08-28 20:13:44,006 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [10/102] ETA 0:00:00 batch={'x': tensor([27, 24]), 'y': tensor([54, 48])} weight=0.518 loss=37.783 lr=['1.667e-03']\n",
      "[2023-08-28 20:13:44,009 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [15/102] ETA 0:00:00 batch={'x': tensor([37, 55]), 'y': tensor([ 74, 110])} weight=0.832 loss=53.705 lr=['1.667e-03']\n",
      "[2023-08-28 20:13:44,013 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [20/102] ETA 0:00:00 batch={'x': tensor([19, 33]), 'y': tensor([38, 66])} weight=1.033 loss=25.133 lr=['1.667e-03']\n",
      "[2023-08-28 20:13:44,016 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [25/102] ETA 0:00:00 batch={'x': tensor([59, 62]), 'y': tensor([118, 124])} weight=1.379 loss=37.560 lr=['1.667e-03']\n",
      "[2023-08-28 20:13:44,019 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [30/102] ETA 0:00:00 batch={'x': tensor([64, 26]), 'y': tensor([128,  52])} weight=1.628 loss=16.725 lr=['1.667e-03']\n",
      "[2023-08-28 20:13:44,023 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [2/3]\n",
      "[2023-08-28 20:13:44,025 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [35/102] ETA 0:00:00 batch={'x': tensor([19, 40]), 'y': tensor([38, 80])} weight=1.922 loss=2.286 lr=['2.000e-03']\n",
      "[2023-08-28 20:13:44,028 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [40/102] ETA 0:00:00 batch={'x': tensor([63, 16]), 'y': tensor([126,  32])} weight=2.089 loss=3.496 lr=['2.000e-03']\n",
      "[2023-08-28 20:13:44,031 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [45/102] ETA 0:00:00 batch={'x': tensor([14, 52]), 'y': tensor([ 28, 104])} weight=2.007 loss=0.214 lr=['2.000e-03']\n",
      "[2023-08-28 20:13:44,034 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [50/102] ETA 0:00:00 batch={'x': tensor([ 7, 15]), 'y': tensor([14, 30])} weight=1.975 loss=0.270 lr=['2.000e-03']\n",
      "[2023-08-28 20:13:44,037 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [55/102] ETA 0:00:00 batch={'x': tensor([50, 59]), 'y': tensor([100, 118])} weight=2.065 loss=3.515 lr=['2.000e-03']\n",
      "[2023-08-28 20:13:44,041 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [60/102] ETA 0:00:00 batch={'x': tensor([26, 54]), 'y': tensor([ 52, 108])} weight=1.980 loss=0.780 lr=['2.000e-03']\n",
      "[2023-08-28 20:13:44,044 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [65/102] ETA 0:00:00 batch={'x': tensor([66, 48]), 'y': tensor([132,  96])} weight=1.933 loss=3.847 lr=['2.000e-03']\n",
      "[2023-08-28 20:13:44,047 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [3/3]\n",
      "[2023-08-28 20:13:44,049 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [70/102] ETA 0:00:00 batch={'x': tensor([25,  3]), 'y': tensor([50,  6])} weight=1.940 loss=0.842 lr=['2.333e-03']\n",
      "[2023-08-28 20:13:44,052 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [75/102] ETA 0:00:00 batch={'x': tensor([46,  6]), 'y': tensor([92, 12])} weight=2.021 loss=0.559 lr=['2.333e-03']\n",
      "[2023-08-28 20:13:44,056 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [80/102] ETA 0:00:00 batch={'x': tensor([54, 56]), 'y': tensor([108, 112])} weight=2.047 loss=2.594 lr=['2.333e-03']\n",
      "[2023-08-28 20:13:44,059 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [85/102] ETA 0:00:00 batch={'x': tensor([29, 59]), 'y': tensor([ 58, 118])} weight=2.060 loss=2.640 lr=['2.333e-03']\n",
      "[2023-08-28 20:13:44,062 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [90/102] ETA 0:00:00 batch={'x': tensor([42, 37]), 'y': tensor([84, 74])} weight=2.045 loss=1.771 lr=['2.333e-03']\n",
      "[2023-08-28 20:13:44,065 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [95/102] ETA 0:00:00 batch={'x': tensor([ 2, 32]), 'y': tensor([ 4, 64])} weight=2.117 loss=1.992 lr=['2.333e-03']\n",
      "[2023-08-28 20:13:44,068 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [100/102] ETA 0:00:00 batch={'x': tensor([48, 60]), 'y': tensor([ 96, 120])} weight=1.997 loss=0.162 lr=['2.333e-03']\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.EpochBasedTrainer = todd.RunnerRegistry.build(\n",
    "        lr_schedule_by_epoch_callback_demo,\n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scaler_callback_demo = iter_based_trainer_demo.copy()\n",
    "lr_scaler_callback = todd.Config(\n",
    "    type='LRScaleCallback',\n",
    "    lr_scaler=dict(base_batch_size=1),\n",
    ")\n",
    "lr_scaler_callback_demo.callbacks = [\n",
    "    optimize_callback,\n",
    "    lr_scaler_callback,\n",
    "    log_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-28 20:13:44,089 36766:140704306648640][lr.py:93 todd.IterBasedTrainer.iter_based_trainer _scale_lr] INFO: base_batch_size=1 batch_size=2 lr_scaler=2.000\n",
      "[2023-08-28 20:13:44,182 36766:140704306648640][log.py:50 todd.IterBasedTrainer.iter_based_trainer init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "\u001b[2m[2023-08-28 20:13:44,184 36766:140704306648640][base.py:54 todd.IterBasedTrainer.iter_based_trainer __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:44,190 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [5/53] ETA 0:00:00 batch={'x': tensor([19, 58]), 'y': tensor([ 38, 116])} weight=1.300 loss=26.950\n",
      "[2023-08-28 20:13:44,193 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [10/53] ETA 0:00:00 batch={'x': tensor([34, 62]), 'y': tensor([ 68, 124])} weight=2.290 loss=13.920\n",
      "[2023-08-28 20:13:44,196 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [15/53] ETA 0:00:00 batch={'x': tensor([24, 14]), 'y': tensor([48, 28])} weight=1.740 loss=4.940\n",
      "[2023-08-28 20:13:44,200 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [20/53] ETA 0:00:00 batch={'x': tensor([48, 56]), 'y': tensor([ 96, 112])} weight=2.305 loss=15.860\n",
      "[2023-08-28 20:13:44,203 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [25/53] ETA 0:00:00 batch={'x': tensor([30,  6]), 'y': tensor([60, 12])} weight=1.920 loss=1.440\n",
      "[2023-08-28 20:13:44,207 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [30/53] ETA 0:00:00 batch={'x': tensor([21, 37]), 'y': tensor([42, 74])} weight=1.830 loss=4.930\n",
      "[2023-08-28 20:13:44,210 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [35/53] ETA 0:00:00 batch={'x': tensor([11, 35]), 'y': tensor([22, 70])} weight=2.055 loss=1.265\n",
      "[2023-08-28 20:13:44,213 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [40/53] ETA 0:00:00 batch={'x': tensor([63, 25]), 'y': tensor([126,  50])} weight=1.770 loss=10.120\n",
      "[2023-08-28 20:13:44,216 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [45/53] ETA 0:00:00 batch={'x': tensor([38, 18]), 'y': tensor([76, 36])} weight=1.895 loss=2.940\n",
      "[2023-08-28 20:13:44,218 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [50/53] ETA 0:00:00 batch={'x': tensor([ 7, 23]), 'y': tensor([14, 46])} weight=2.015 loss=0.225\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.IterBasedTrainer = todd.RunnerRegistry.build(\n",
    "        lr_scaler_callback_demo,\n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback_demo = iter_based_trainer_demo.copy()\n",
    "checkpoint_callback = todd.Config(type='CheckpointCallback', interval=10)\n",
    "checkpoint_callback_demo.callbacks = [checkpoint_callback, log_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-28 20:13:44,340 36766:140704306648640][log.py:50 todd.IterBasedTrainer.iter_based_trainer init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "\u001b[2m[2023-08-28 20:13:44,343 36766:140704306648640][base.py:54 todd.IterBasedTrainer.iter_based_trainer __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:44,347 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [5/53] ETA 0:00:00 batch={'x': tensor([61, 14]), 'y': tensor([122,  28])} weight=0.000 loss=75.000\n",
      "[2023-08-28 20:13:44,350 36766:140704306648640][checkpoint.py:61 todd.IterBasedTrainer.iter_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp574yfv_q/iter_based_trainer/checkpoints/iter_10\n",
      "[2023-08-28 20:13:44,354 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [10/53] ETA 0:00:00 batch={'x': tensor([48, 40]), 'y': tensor([96, 80])} weight=0.000 loss=88.000\n",
      "[2023-08-28 20:13:44,357 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [15/53] ETA 0:00:00 batch={'x': tensor([51, 35]), 'y': tensor([102,  70])} weight=0.000 loss=86.000\n",
      "[2023-08-28 20:13:44,360 36766:140704306648640][checkpoint.py:61 todd.IterBasedTrainer.iter_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp574yfv_q/iter_based_trainer/checkpoints/iter_20\n",
      "[2023-08-28 20:13:44,363 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [20/53] ETA 0:00:00 batch={'x': tensor([17,  4]), 'y': tensor([34,  8])} weight=0.000 loss=21.000\n",
      "[2023-08-28 20:13:44,366 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [25/53] ETA 0:00:00 batch={'x': tensor([27, 16]), 'y': tensor([54, 32])} weight=0.000 loss=43.000\n",
      "[2023-08-28 20:13:44,370 36766:140704306648640][checkpoint.py:61 todd.IterBasedTrainer.iter_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp574yfv_q/iter_based_trainer/checkpoints/iter_30\n",
      "[2023-08-28 20:13:44,409 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [30/53] ETA 0:00:00 batch={'x': tensor([21, 12]), 'y': tensor([42, 24])} weight=0.000 loss=33.000\n",
      "[2023-08-28 20:13:44,418 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [35/53] ETA 0:00:00 batch={'x': tensor([34, 65]), 'y': tensor([ 68, 130])} weight=0.000 loss=99.000\n",
      "[2023-08-28 20:13:44,421 36766:140704306648640][checkpoint.py:61 todd.IterBasedTrainer.iter_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp574yfv_q/iter_based_trainer/checkpoints/iter_40\n",
      "[2023-08-28 20:13:44,425 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [40/53] ETA 0:00:00 batch={'x': tensor([ 2, 46]), 'y': tensor([ 4, 92])} weight=0.000 loss=48.000\n",
      "[2023-08-28 20:13:44,429 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [45/53] ETA 0:00:00 batch={'x': tensor([ 7, 62]), 'y': tensor([ 14, 124])} weight=0.000 loss=69.000\n",
      "[2023-08-28 20:13:44,433 36766:140704306648640][checkpoint.py:61 todd.IterBasedTrainer.iter_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp574yfv_q/iter_based_trainer/checkpoints/iter_50\n",
      "[2023-08-28 20:13:44,439 36766:140704306648640][log.py:84 todd.IterBasedTrainer.iter_based_trainer after_run_iter] INFO: Iter [50/53] ETA 0:00:00 batch={'x': tensor([10,  8]), 'y': tensor([20, 16])} weight=0.000 loss=18.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36m/var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp574yfv_q\u001b[0m\n",
      "└── \u001b[1;36miter_based_trainer\u001b[0m\n",
      "    ├── 2023-08-28T20-13-44_247631-08-00.log\n",
      "    └── \u001b[1;36mcheckpoints\u001b[0m\n",
      "        ├── \u001b[1;36miter_10\u001b[0m\n",
      "        │   ├── callbacks.pth\n",
      "        │   ├── meta.pth\n",
      "        │   ├── model.pth\n",
      "        │   ├── optim.pth\n",
      "        │   └── strategy.pth\n",
      "        ├── \u001b[1;36miter_20\u001b[0m\n",
      "        │   ├── callbacks.pth\n",
      "        │   ├── meta.pth\n",
      "        │   ├── model.pth\n",
      "        │   ├── optim.pth\n",
      "        │   └── strategy.pth\n",
      "        ├── \u001b[1;36miter_30\u001b[0m\n",
      "        │   ├── callbacks.pth\n",
      "        │   ├── meta.pth\n",
      "        │   ├── model.pth\n",
      "        │   ├── optim.pth\n",
      "        │   └── strategy.pth\n",
      "        ├── \u001b[1;36miter_40\u001b[0m\n",
      "        │   ├── callbacks.pth\n",
      "        │   ├── meta.pth\n",
      "        │   ├── model.pth\n",
      "        │   ├── optim.pth\n",
      "        │   └── strategy.pth\n",
      "        ├── \u001b[1;36miter_50\u001b[0m\n",
      "        │   ├── callbacks.pth\n",
      "        │   ├── meta.pth\n",
      "        │   ├── model.pth\n",
      "        │   ├── optim.pth\n",
      "        │   └── strategy.pth\n",
      "        └── \u001b[35mlatest\u001b[0m -> \u001b[1;36miter_50\u001b[0m\n",
      "\n",
      "9 directories, 26 files\n",
      "\n",
      "strategy.pth:\n",
      "{}\n",
      "\n",
      "optim.pth:\n",
      "{'param_groups': [{'dampening': 0,\n",
      "                   'differentiable': False,\n",
      "                   'foreach': None,\n",
      "                   'lr': 0.005,\n",
      "                   'maximize': False,\n",
      "                   'momentum': 0,\n",
      "                   'nesterov': False,\n",
      "                   'params': [0],\n",
      "                   'weight_decay': 0}],\n",
      " 'state': {}}\n",
      "\n",
      "meta.pth:\n",
      "{'iter_': 50}\n",
      "\n",
      "model.pth:\n",
      "OrderedDict([('_weight', tensor(0.))])\n",
      "\n",
      "callbacks.pth:\n",
      "{'callbacks': [{}, {}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.IterBasedTrainer = todd.RunnerRegistry.build(\n",
    "        checkpoint_callback_demo, \n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.run()\n",
    "\n",
    "    !echo\n",
    "    !tree {work_dirs}\n",
    "    !echo\n",
    "\n",
    "    iter_50 = pathlib.Path(work_dirs) / 'iter_based_trainer' / 'checkpoints' / 'iter_50'\n",
    "    for f in iter_50.glob('*.pth'):\n",
    "        print(f\"{f.name}:\")\n",
    "        pprint(torch.load(f, 'cpu'))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_by_epoch_callback_demo = epoch_based_trainer_demo.copy()\n",
    "checkpoint_by_epoch_callback = checkpoint_callback.copy()\n",
    "checkpoint_by_epoch_callback.update(interval=1, by_epoch=True)\n",
    "checkpoint_by_epoch_callback_demo.callbacks = [\n",
    "    checkpoint_by_epoch_callback,\n",
    "    log_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-28 20:13:44,969 36766:140704306648640][log.py:50 todd.EpochBasedTrainer.epoch_based_trainer init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "\u001b[2m[2023-08-28 20:13:44,971 36766:140704306648640][base.py:54 todd.EpochBasedTrainer.epoch_based_trainer __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:44,973 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [1/3]\n",
      "[2023-08-28 20:13:44,978 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [5/102] ETA 0:00:00 batch={'x': tensor([26, 31]), 'y': tensor([52, 62])} weight=0.000 loss=57.000\n",
      "[2023-08-28 20:13:44,981 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [10/102] ETA 0:00:00 batch={'x': tensor([16, 39]), 'y': tensor([32, 78])} weight=0.000 loss=55.000\n",
      "[2023-08-28 20:13:44,983 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [15/102] ETA 0:00:00 batch={'x': tensor([ 8, 56]), 'y': tensor([ 16, 112])} weight=0.000 loss=64.000\n",
      "[2023-08-28 20:13:44,986 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [20/102] ETA 0:00:00 batch={'x': tensor([62, 55]), 'y': tensor([124, 110])} weight=0.000 loss=117.000\n",
      "[2023-08-28 20:13:44,988 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [25/102] ETA 0:00:00 batch={'x': tensor([52, 12]), 'y': tensor([104,  24])} weight=0.000 loss=64.000\n",
      "[2023-08-28 20:13:44,990 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [30/102] ETA 0:00:00 batch={'x': tensor([18, 61]), 'y': tensor([ 36, 122])} weight=0.000 loss=79.000\n",
      "[2023-08-28 20:13:44,993 36766:140704306648640][checkpoint.py:61 todd.EpochBasedTrainer.epoch_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmpbtgrtc_u/epoch_based_trainer/checkpoints/epoch_1\n",
      "[2023-08-28 20:13:44,997 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [2/3]\n",
      "[2023-08-28 20:13:44,999 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [35/102] ETA 0:00:00 batch={'x': tensor([9, 7]), 'y': tensor([18, 14])} weight=0.000 loss=16.000\n",
      "[2023-08-28 20:13:45,001 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [40/102] ETA 0:00:00 batch={'x': tensor([36, 25]), 'y': tensor([72, 50])} weight=0.000 loss=61.000\n",
      "[2023-08-28 20:13:45,003 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [45/102] ETA 0:00:00 batch={'x': tensor([67, 46]), 'y': tensor([134,  92])} weight=0.000 loss=113.000\n",
      "[2023-08-28 20:13:45,006 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [50/102] ETA 0:00:00 batch={'x': tensor([66, 33]), 'y': tensor([132,  66])} weight=0.000 loss=99.000\n",
      "[2023-08-28 20:13:45,008 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [55/102] ETA 0:00:00 batch={'x': tensor([62, 30]), 'y': tensor([124,  60])} weight=0.000 loss=92.000\n",
      "[2023-08-28 20:13:45,011 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [60/102] ETA 0:00:00 batch={'x': tensor([18,  3]), 'y': tensor([36,  6])} weight=0.000 loss=21.000\n",
      "[2023-08-28 20:13:45,013 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [65/102] ETA 0:00:00 batch={'x': tensor([55, 22]), 'y': tensor([110,  44])} weight=0.000 loss=77.000\n",
      "[2023-08-28 20:13:45,016 36766:140704306648640][checkpoint.py:61 todd.EpochBasedTrainer.epoch_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmpbtgrtc_u/epoch_based_trainer/checkpoints/epoch_2\n",
      "[2023-08-28 20:13:45,019 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [3/3]\n",
      "[2023-08-28 20:13:45,021 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [70/102] ETA 0:00:00 batch={'x': tensor([46, 51]), 'y': tensor([ 92, 102])} weight=0.000 loss=97.000\n",
      "[2023-08-28 20:13:45,024 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [75/102] ETA 0:00:00 batch={'x': tensor([19, 60]), 'y': tensor([ 38, 120])} weight=0.000 loss=79.000\n",
      "[2023-08-28 20:13:45,026 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [80/102] ETA 0:00:00 batch={'x': tensor([45,  9]), 'y': tensor([90, 18])} weight=0.000 loss=54.000\n",
      "[2023-08-28 20:13:45,028 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [85/102] ETA 0:00:00 batch={'x': tensor([12, 34]), 'y': tensor([24, 68])} weight=0.000 loss=46.000\n",
      "[2023-08-28 20:13:45,031 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [90/102] ETA 0:00:00 batch={'x': tensor([52,  4]), 'y': tensor([104,   8])} weight=0.000 loss=56.000\n",
      "[2023-08-28 20:13:45,033 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [95/102] ETA 0:00:00 batch={'x': tensor([39, 35]), 'y': tensor([78, 70])} weight=0.000 loss=74.000\n",
      "[2023-08-28 20:13:45,035 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [100/102] ETA 0:00:00 batch={'x': tensor([22, 54]), 'y': tensor([ 44, 108])} weight=0.000 loss=76.000\n",
      "[2023-08-28 20:13:45,038 36766:140704306648640][checkpoint.py:61 todd.EpochBasedTrainer.epoch_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmpbtgrtc_u/epoch_based_trainer/checkpoints/epoch_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36m/var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmpbtgrtc_u\u001b[0m\n",
      "└── \u001b[1;36mepoch_based_trainer\u001b[0m\n",
      "    ├── 2023-08-28T20-13-44_874198-08-00.log\n",
      "    └── \u001b[1;36mcheckpoints\u001b[0m\n",
      "        ├── \u001b[1;36mepoch_1\u001b[0m\n",
      "        │   ├── callbacks.pth\n",
      "        │   ├── meta.pth\n",
      "        │   ├── model.pth\n",
      "        │   ├── optim.pth\n",
      "        │   └── strategy.pth\n",
      "        ├── \u001b[1;36mepoch_2\u001b[0m\n",
      "        │   ├── callbacks.pth\n",
      "        │   ├── meta.pth\n",
      "        │   ├── model.pth\n",
      "        │   ├── optim.pth\n",
      "        │   └── strategy.pth\n",
      "        ├── \u001b[1;36mepoch_3\u001b[0m\n",
      "        │   ├── callbacks.pth\n",
      "        │   ├── meta.pth\n",
      "        │   ├── model.pth\n",
      "        │   ├── optim.pth\n",
      "        │   └── strategy.pth\n",
      "        └── \u001b[35mlatest\u001b[0m -> \u001b[1;36mepoch_3\u001b[0m\n",
      "\n",
      "7 directories, 16 files\n",
      "\n",
      "strategy.pth:\n",
      "{}\n",
      "\n",
      "optim.pth:\n",
      "{'param_groups': [{'dampening': 0,\n",
      "                   'differentiable': False,\n",
      "                   'foreach': None,\n",
      "                   'lr': 0.005,\n",
      "                   'maximize': False,\n",
      "                   'momentum': 0,\n",
      "                   'nesterov': False,\n",
      "                   'params': [0],\n",
      "                   'weight_decay': 0}],\n",
      " 'state': {}}\n",
      "\n",
      "meta.pth:\n",
      "{'epoch': 2, 'iter_': 68}\n",
      "\n",
      "model.pth:\n",
      "OrderedDict([('_weight', tensor(0.))])\n",
      "\n",
      "callbacks.pth:\n",
      "{'callbacks': [{}, {}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.EpochBasedTrainer = todd.RunnerRegistry.build(\n",
    "        checkpoint_by_epoch_callback_demo, \n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.run()\n",
    "\n",
    "    !echo\n",
    "    !tree {work_dirs}\n",
    "    !echo\n",
    "\n",
    "    epoch_2 = pathlib.Path(work_dirs) / 'epoch_based_trainer' / 'checkpoints' / 'epoch_2'\n",
    "    for f in epoch_2.glob('*.pth'):\n",
    "        print(f\"{f.name}:\")\n",
    "        pprint(torch.load(f, 'cpu'))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_load_from_callback_demo = checkpoint_by_epoch_callback_demo.copy()\n",
    "checkpoint_load_from_callback_demo.callbacks = [\n",
    "    optimize_callback,\n",
    "    checkpoint_by_epoch_callback,\n",
    "    log_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-28 20:13:45,567 36766:140704306648640][log.py:50 todd.EpochBasedTrainer.epoch_based_trainer init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "\u001b[2m[2023-08-28 20:13:45,569 36766:140704306648640][base.py:54 todd.EpochBasedTrainer.epoch_based_trainer __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:45,571 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [1/3]\n",
      "[2023-08-28 20:13:45,576 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [5/102] ETA 0:00:00 batch={'x': tensor([44, 15]), 'y': tensor([88, 30])} weight=0.690 loss=38.645\n",
      "[2023-08-28 20:13:45,580 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [10/102] ETA 0:00:00 batch={'x': tensor([33, 31]), 'y': tensor([66, 62])} weight=1.632 loss=11.760\n",
      "[2023-08-28 20:13:45,584 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [15/102] ETA 0:00:00 batch={'x': tensor([13, 25]), 'y': tensor([26, 50])} weight=1.807 loss=3.658\n",
      "[2023-08-28 20:13:45,587 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [20/102] ETA 0:00:00 batch={'x': tensor([58,  7]), 'y': tensor([116,  14])} weight=2.207 loss=6.744\n",
      "[2023-08-28 20:13:45,590 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [25/102] ETA 0:00:00 batch={'x': tensor([ 8, 28]), 'y': tensor([16, 56])} weight=2.132 loss=2.385\n",
      "[2023-08-28 20:13:45,594 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [30/102] ETA 0:00:00 batch={'x': tensor([20, 50]), 'y': tensor([ 40, 100])} weight=2.158 loss=5.513\n",
      "[2023-08-28 20:13:45,600 36766:140704306648640][checkpoint.py:61 todd.EpochBasedTrainer.epoch_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmpq64o21fc/epoch_based_trainer/checkpoints/epoch_1\n",
      "[2023-08-28 20:13:45,644 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [2/3]\n",
      "[2023-08-28 20:13:45,648 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [35/102] ETA 0:00:00 batch={'x': tensor([60, 51]), 'y': tensor([120, 102])} weight=2.190 loss=10.545\n",
      "[2023-08-28 20:13:45,651 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [40/102] ETA 0:00:00 batch={'x': tensor([45,  7]), 'y': tensor([90, 14])} weight=2.100 loss=2.600\n",
      "[2023-08-28 20:13:45,655 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [45/102] ETA 0:00:00 batch={'x': tensor([26, 66]), 'y': tensor([ 52, 132])} weight=1.973 loss=1.265\n",
      "[2023-08-28 20:13:45,668 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [50/102] ETA 0:00:00 batch={'x': tensor([38,  1]), 'y': tensor([76,  2])} weight=1.805 loss=3.802\n",
      "[2023-08-28 20:13:45,671 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [55/102] ETA 0:00:00 batch={'x': tensor([43,  9]), 'y': tensor([86, 18])} weight=1.915 loss=2.210\n",
      "[2023-08-28 20:13:45,675 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [60/102] ETA 0:00:00 batch={'x': tensor([17, 39]), 'y': tensor([34, 78])} weight=2.072 loss=2.030\n",
      "[2023-08-28 20:13:45,678 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [65/102] ETA 0:00:00 batch={'x': tensor([52, 32]), 'y': tensor([104,  64])} weight=2.045 loss=1.890\n",
      "[2023-08-28 20:13:45,681 36766:140704306648640][checkpoint.py:61 todd.EpochBasedTrainer.epoch_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmpq64o21fc/epoch_based_trainer/checkpoints/epoch_2\n",
      "[2023-08-28 20:13:45,684 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [3/3]\n",
      "[2023-08-28 20:13:45,686 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [70/102] ETA 0:00:00 batch={'x': tensor([51, 25]), 'y': tensor([102,  50])} weight=1.898 loss=3.895\n",
      "[2023-08-28 20:13:45,690 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [75/102] ETA 0:00:00 batch={'x': tensor([14, 28]), 'y': tensor([28, 56])} weight=2.045 loss=0.945\n",
      "[2023-08-28 20:13:45,693 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [80/102] ETA 0:00:00 batch={'x': tensor([42, 34]), 'y': tensor([84, 68])} weight=1.792 loss=7.885\n",
      "[2023-08-28 20:13:45,696 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [85/102] ETA 0:00:00 batch={'x': tensor([33, 56]), 'y': tensor([ 66, 112])} weight=1.782 loss=9.679\n",
      "[2023-08-28 20:13:45,699 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [90/102] ETA 0:00:00 batch={'x': tensor([ 7, 24]), 'y': tensor([14, 48])} weight=1.832 loss=2.596\n",
      "[2023-08-28 20:13:45,702 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [95/102] ETA 0:00:00 batch={'x': tensor([62, 10]), 'y': tensor([124,  20])} weight=2.005 loss=0.180\n",
      "[2023-08-28 20:13:45,705 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [100/102] ETA 0:00:00 batch={'x': tensor([ 5, 36]), 'y': tensor([10, 72])} weight=1.975 loss=0.513\n",
      "[2023-08-28 20:13:45,708 36766:140704306648640][checkpoint.py:61 todd.EpochBasedTrainer.epoch_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmpq64o21fc/epoch_based_trainer/checkpoints/epoch_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-28 20:13:46,099 36766:140704306648640][checkpoint.py:46 todd.EpochBasedTrainer.epoch_based_trainer init] INFO: Loading from /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmpq64o21fc/epoch_based_trainer/checkpoints/epoch_2\n",
      "[2023-08-28 20:13:46,103 36766:140704306648640][base.py:62 todd.EpochBasedTrainer.epoch_based_trainer load_model_state_dict] INFO: <All keys matched successfully>\n",
      "[2023-08-28 20:13:46,191 36766:140704306648640][log.py:50 todd.EpochBasedTrainer.epoch_based_trainer init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "\u001b[2m[2023-08-28 20:13:46,193 36766:140704306648640][base.py:54 todd.EpochBasedTrainer.epoch_based_trainer __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:46,194 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [3/3]\n",
      "[2023-08-28 20:13:46,199 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [70/102] ETA 0:00:00 batch={'x': tensor([13, 67]), 'y': tensor([ 26, 134])} weight=1.938 loss=2.500\n",
      "[2023-08-28 20:13:46,202 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [75/102] ETA 0:00:00 batch={'x': tensor([56, 28]), 'y': tensor([112,  56])} weight=1.933 loss=2.835\n",
      "[2023-08-28 20:13:46,206 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [80/102] ETA 0:00:00 batch={'x': tensor([50, 52]), 'y': tensor([100, 104])} weight=1.928 loss=3.697\n",
      "[2023-08-28 20:13:46,210 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [85/102] ETA 0:00:00 batch={'x': tensor([25, 46]), 'y': tensor([50, 92])} weight=2.208 loss=7.366\n",
      "[2023-08-28 20:13:46,213 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [90/102] ETA 0:00:00 batch={'x': tensor([11, 21]), 'y': tensor([22, 42])} weight=1.840 loss=2.560\n",
      "[2023-08-28 20:13:46,216 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [95/102] ETA 0:00:00 batch={'x': tensor([17, 18]), 'y': tensor([34, 36])} weight=1.838 loss=2.844\n",
      "[2023-08-28 20:13:46,219 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [100/102] ETA 0:00:00 batch={'x': tensor([30, 45]), 'y': tensor([60, 90])} weight=2.090 loss=3.375\n",
      "[2023-08-28 20:13:46,222 36766:140704306648640][checkpoint.py:61 todd.EpochBasedTrainer.epoch_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmpq64o21fc/epoch_based_trainer/checkpoints/epoch_3\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.EpochBasedTrainer = todd.RunnerRegistry.build(\n",
    "        checkpoint_load_from_callback_demo, \n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.run()\n",
    "\n",
    "    !echo\n",
    "    !echo {'-' * 20}\n",
    "    !echo\n",
    "\n",
    "    runner: todd.runners.EpochBasedTrainer = todd.RunnerRegistry.build(\n",
    "        checkpoint_load_from_callback_demo, \n",
    "        work_dir=dict(root=work_dirs),\n",
    "        load_from=os.path.join(work_dirs, 'epoch_based_trainer', 'checkpoints', 'epoch_2')\n",
    "    )\n",
    "    runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomError(RuntimeError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@todd.RunnerRegistry.register()\n",
    "class FaultyValidator(todd.runners.Validator):\n",
    "\n",
    "    def _run_iter(self, *args, **kwargs) -> NoReturn:\n",
    "        raise CustomError('faulty runner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_callback_demo = validator_demo.copy()\n",
    "monitor_callback_demo.type = 'FaultyValidator'\n",
    "monitor_callback = todd.Config(type='MonitorCallback')\n",
    "monitor_callback_demo.callbacks = [monitor_callback, log_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-28 20:13:46,361 36766:140704306648640][log.py:50 todd.FaultyValidator.validator init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "\u001b[2m[2023-08-28 20:13:46,363 36766:140704306648640][base.py:54 todd.FaultyValidator.validator __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "\u001b[1;31m[2023-08-28 20:13:46,366 36766:140704306648640][monitor.py:28 todd.FaultyValidator.validator __exit__] ERROR: Unable to run iter_=1\n",
      "batch={'x': tensor([1]), 'y': tensor([2])}\n",
      "memo={'dataloader': <torch.utils.data.dataloader.DataLoader object at 0x152a8f4d0>}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages/todd/runners/base.py\", line 197, in _run\n",
      "    memo = self._run_iter(batch, memo)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/ipykernel_36766/2965682526.py\", line 5, in _run_iter\n",
      "    raise CustomError('faulty runner')\n",
      "CustomError: faulty runner\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2023-08-28 20:13:46,361 36766:140704306648640][log.py:50 todd.FaultyValidator.validator init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "[2023-08-28 20:13:46,363 36766:140704306648640][base.py:54 todd.FaultyValidator.validator __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\n",
      "[2023-08-28 20:13:46,366 36766:140704306648640][monitor.py:28 todd.FaultyValidator.validator __exit__] ERROR: Unable to run iter_=1\n",
      "batch={'x': tensor([1]), 'y': tensor([2])}\n",
      "memo={'dataloader': <torch.utils.data.dataloader.DataLoader object at 0x152a8f4d0>}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bytedance/.local/share/virtualenvs/todd-ARrcnwyq/lib/python3.11/site-packages/todd/runners/base.py\", line 197, in _run\n",
      "    memo = self._run_iter(batch, memo)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/ipykernel_36766/2965682526.py\", line 5, in _run_iter\n",
      "    raise CustomError('faulty runner')\n",
      "CustomError: faulty runner\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.Validator = todd.RunnerRegistry.build(\n",
    "        monitor_callback_demo, \n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    try:\n",
    "        runner.run()\n",
    "    except CustomError as e:\n",
    "        pass\n",
    "\n",
    "    !echo\n",
    "    !cat {work_dirs}/validator/*.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priorities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_load_model_from_demo = checkpoint_load_from_callback_demo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-28 20:13:46,753 36766:140704306648640][log.py:50 todd.EpochBasedTrainer.epoch_based_trainer init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "\u001b[2m[2023-08-28 20:13:46,755 36766:140704306648640][base.py:54 todd.EpochBasedTrainer.epoch_based_trainer __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:46,756 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [1/3]\n",
      "[2023-08-28 20:13:46,762 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [5/102] ETA 0:00:00 batch={'x': tensor([11, 52]), 'y': tensor([ 22, 104])} weight=0.410 loss=50.085\n",
      "[2023-08-28 20:13:46,766 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [10/102] ETA 0:00:00 batch={'x': tensor([14, 50]), 'y': tensor([ 28, 100])} weight=1.278 loss=23.120\n",
      "[2023-08-28 20:13:46,769 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [15/102] ETA 0:00:00 batch={'x': tensor([23, 57]), 'y': tensor([ 46, 114])} weight=1.998 loss=0.100\n",
      "[2023-08-28 20:13:46,774 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [20/102] ETA 0:00:00 batch={'x': tensor([60,  2]), 'y': tensor([120,   4])} weight=1.915 loss=2.635\n",
      "[2023-08-28 20:13:46,779 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [25/102] ETA 0:00:00 batch={'x': tensor([19, 61]), 'y': tensor([ 38, 122])} weight=1.940 loss=2.400\n",
      "[2023-08-28 20:13:46,783 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [30/102] ETA 0:00:00 batch={'x': tensor([42, 46]), 'y': tensor([84, 92])} weight=2.240 loss=10.560\n",
      "[2023-08-28 20:13:46,787 36766:140704306648640][checkpoint.py:61 todd.EpochBasedTrainer.epoch_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp342oklit/epoch_based_trainer/checkpoints/epoch_1\n",
      "[2023-08-28 20:13:46,790 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [2/3]\n",
      "[2023-08-28 20:13:46,793 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [35/102] ETA 0:00:00 batch={'x': tensor([ 7, 48]), 'y': tensor([14, 96])} weight=1.975 loss=0.687\n",
      "[2023-08-28 20:13:46,797 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [40/102] ETA 0:00:00 batch={'x': tensor([38, 60]), 'y': tensor([ 76, 120])} weight=2.038 loss=1.838\n",
      "[2023-08-28 20:13:46,801 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [45/102] ETA 0:00:00 batch={'x': tensor([61, 40]), 'y': tensor([122,  80])} weight=2.173 loss=8.711\n",
      "[2023-08-28 20:13:46,804 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [50/102] ETA 0:00:00 batch={'x': tensor([37, 21]), 'y': tensor([74, 42])} weight=2.055 loss=1.595\n",
      "[2023-08-28 20:13:46,808 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [55/102] ETA 0:00:00 batch={'x': tensor([63, 24]), 'y': tensor([126,  48])} weight=2.068 loss=2.936\n",
      "[2023-08-28 20:13:46,811 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [60/102] ETA 0:00:00 batch={'x': tensor([64, 20]), 'y': tensor([128,  40])} weight=2.115 loss=4.830\n",
      "[2023-08-28 20:13:46,816 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [65/102] ETA 0:00:00 batch={'x': tensor([57, 18]), 'y': tensor([114,  36])} weight=1.963 loss=1.406\n",
      "[2023-08-28 20:13:46,820 36766:140704306648640][checkpoint.py:61 todd.EpochBasedTrainer.epoch_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp342oklit/epoch_based_trainer/checkpoints/epoch_2\n",
      "[2023-08-28 20:13:46,824 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [3/3]\n",
      "[2023-08-28 20:13:46,827 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [70/102] ETA 0:00:00 batch={'x': tensor([64, 16]), 'y': tensor([128,  32])} weight=1.938 loss=2.500\n",
      "[2023-08-28 20:13:46,831 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [75/102] ETA 0:00:00 batch={'x': tensor([14, 40]), 'y': tensor([28, 80])} weight=2.013 loss=0.338\n",
      "[2023-08-28 20:13:46,835 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [80/102] ETA 0:00:00 batch={'x': tensor([63, 23]), 'y': tensor([126,  46])} weight=1.770 loss=9.890\n",
      "[2023-08-28 20:13:46,839 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [85/102] ETA 0:00:00 batch={'x': tensor([49, 57]), 'y': tensor([ 98, 114])} weight=2.188 loss=9.938\n",
      "[2023-08-28 20:13:46,842 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [90/102] ETA 0:00:00 batch={'x': tensor([11,  8]), 'y': tensor([22, 16])} weight=2.150 loss=1.425\n",
      "[2023-08-28 20:13:46,846 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [95/102] ETA 0:00:00 batch={'x': tensor([66, 35]), 'y': tensor([132,  70])} weight=2.050 loss=2.525\n",
      "[2023-08-28 20:13:46,850 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [100/102] ETA 0:00:00 batch={'x': tensor([38, 61]), 'y': tensor([ 76, 122])} weight=2.163 loss=8.044\n",
      "[2023-08-28 20:13:46,852 36766:140704306648640][checkpoint.py:61 todd.EpochBasedTrainer.epoch_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp342oklit/epoch_based_trainer/checkpoints/epoch_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-28 20:13:47,331 36766:140704306648640][log.py:50 todd.EpochBasedTrainer.epoch_based_trainer init] INFO: \n",
      "Platform: macOS-13.4.1\n",
      "NVIDIA SMI: None\n",
      "Python version: 3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "PyTorch version: 2.0.1\n",
      "TorchVision version: 0.15.2\n",
      "OpenCV version: 4.7.0\n",
      "Todd version: 0.4.0\n",
      "CUDA_HOME: None\n",
      "Git commit ID: dcd00d8\n",
      "Git status: \n",
      "M todd/runners/base.py\n",
      " M todd/runners/callbacks/optimize.py\n",
      " M todd/runners/callbacks/tensorboard.py\n",
      " M todd/runners/epoch_based_trainer.py\n",
      " M todd/runners/iter_based_trainer.py\n",
      " M todd/runners/trainer.py\n",
      " M todd/runners/validator.py\n",
      " M tutorials/runners.ipynb\n",
      "\u001b[2m[2023-08-28 20:13:47,333 36766:140704306648640][base.py:54 todd.EpochBasedTrainer.epoch_based_trainer __init__] DEBUG: Rank 0 initialized by bytedance@C02G870SMD6R\u001b[m\n",
      "[2023-08-28 20:13:47,334 36766:140704306648640][base.py:65 todd.EpochBasedTrainer.epoch_based_trainer load_model_from] INFO: Loading model from /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp342oklit/epoch_based_trainer/checkpoints/epoch_2/model.pth\n",
      "[2023-08-28 20:13:47,337 36766:140704306648640][base.py:62 todd.EpochBasedTrainer.epoch_based_trainer load_model_state_dict] INFO: <All keys matched successfully>\n",
      "[2023-08-28 20:13:47,338 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [1/3]\n",
      "[2023-08-28 20:13:47,343 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [5/102] ETA 0:00:00 batch={'x': tensor([ 1, 10]), 'y': tensor([ 2, 20])} weight=2.080 loss=0.440\n",
      "[2023-08-28 20:13:47,347 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [10/102] ETA 0:00:00 batch={'x': tensor([27, 53]), 'y': tensor([ 54, 106])} weight=2.000 loss=0.000\n",
      "[2023-08-28 20:13:47,352 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [15/102] ETA 0:00:00 batch={'x': tensor([14, 57]), 'y': tensor([ 28, 114])} weight=1.958 loss=1.509\n",
      "[2023-08-28 20:13:47,356 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [20/102] ETA 0:00:00 batch={'x': tensor([19, 42]), 'y': tensor([38, 84])} weight=1.790 loss=6.405\n",
      "[2023-08-28 20:13:47,360 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [25/102] ETA 0:00:00 batch={'x': tensor([15, 51]), 'y': tensor([ 30, 102])} weight=1.815 loss=6.105\n",
      "[2023-08-28 20:13:47,372 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [30/102] ETA 0:00:00 batch={'x': tensor([60, 66]), 'y': tensor([120, 132])} weight=1.890 loss=6.930\n",
      "[2023-08-28 20:13:47,407 36766:140704306648640][checkpoint.py:61 todd.EpochBasedTrainer.epoch_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp342oklit/epoch_based_trainer/checkpoints/epoch_1\n",
      "[2023-08-28 20:13:47,421 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [2/3]\n",
      "[2023-08-28 20:13:47,423 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [35/102] ETA 0:00:00 batch={'x': tensor([36, 50]), 'y': tensor([ 72, 100])} weight=2.013 loss=0.538\n",
      "[2023-08-28 20:13:47,427 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [40/102] ETA 0:00:00 batch={'x': tensor([54,  8]), 'y': tensor([108,  16])} weight=2.055 loss=1.705\n",
      "[2023-08-28 20:13:47,432 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [45/102] ETA 0:00:00 batch={'x': tensor([38, 25]), 'y': tensor([76, 50])} weight=2.070 loss=2.205\n",
      "[2023-08-28 20:13:47,441 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [50/102] ETA 0:00:00 batch={'x': tensor([56, 53]), 'y': tensor([112, 106])} weight=1.908 loss=5.041\n",
      "[2023-08-28 20:13:47,446 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [55/102] ETA 0:00:00 batch={'x': tensor([22, 17]), 'y': tensor([44, 34])} weight=1.905 loss=1.852\n",
      "[2023-08-28 20:13:47,450 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [60/102] ETA 0:00:00 batch={'x': tensor([41,  6]), 'y': tensor([82, 12])} weight=2.030 loss=0.705\n",
      "[2023-08-28 20:13:47,453 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [65/102] ETA 0:00:00 batch={'x': tensor([32,  2]), 'y': tensor([64,  4])} weight=1.905 loss=1.615\n",
      "[2023-08-28 20:13:47,456 36766:140704306648640][checkpoint.py:61 todd.EpochBasedTrainer.epoch_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp342oklit/epoch_based_trainer/checkpoints/epoch_2\n",
      "[2023-08-28 20:13:47,459 36766:140704306648640][log.py:90 todd.EpochBasedTrainer.epoch_based_trainer before_run_epoch] INFO: Epoch [3/3]\n",
      "[2023-08-28 20:13:47,463 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [70/102] ETA 0:00:00 batch={'x': tensor([40, 27]), 'y': tensor([80, 54])} weight=1.960 loss=1.340\n",
      "[2023-08-28 20:13:47,467 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [75/102] ETA 0:00:00 batch={'x': tensor([36, 29]), 'y': tensor([72, 58])} weight=2.155 loss=5.038\n",
      "[2023-08-28 20:13:47,471 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [80/102] ETA 0:00:00 batch={'x': tensor([18, 35]), 'y': tensor([36, 70])} weight=2.083 loss=2.186\n",
      "[2023-08-28 20:13:47,475 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [85/102] ETA 0:00:00 batch={'x': tensor([41, 64]), 'y': tensor([ 82, 128])} weight=2.048 loss=2.494\n",
      "[2023-08-28 20:13:47,479 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [90/102] ETA 0:00:00 batch={'x': tensor([46,  4]), 'y': tensor([92,  8])} weight=2.085 loss=2.125\n",
      "[2023-08-28 20:13:47,483 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [95/102] ETA 0:00:00 batch={'x': tensor([16, 28]), 'y': tensor([32, 56])} weight=1.818 loss=4.015\n",
      "[2023-08-28 20:13:47,486 36766:140704306648640][log.py:84 todd.EpochBasedTrainer.epoch_based_trainer after_run_iter] INFO: Iter [100/102] ETA 0:00:00 batch={'x': tensor([15, 51]), 'y': tensor([ 30, 102])} weight=2.175 loss=5.775\n",
      "[2023-08-28 20:13:47,488 36766:140704306648640][checkpoint.py:61 todd.EpochBasedTrainer.epoch_based_trainer _save] INFO: Saving state dict to /var/folders/v_/1kkfntxs5z74_rwvy1f3_mp80000gn/T/tmp342oklit/epoch_based_trainer/checkpoints/epoch_3\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as work_dirs:\n",
    "    runner: todd.runners.EpochBasedTrainer = todd.RunnerRegistry.build(\n",
    "        strategy_load_model_from_demo, \n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.run()\n",
    "\n",
    "    !echo\n",
    "    !echo {'-' * 20}\n",
    "    !echo\n",
    "\n",
    "    runner: todd.runners.EpochBasedTrainer = todd.RunnerRegistry.build(\n",
    "        strategy_load_model_from_demo, \n",
    "        work_dir=dict(root=work_dirs),\n",
    "    )\n",
    "    runner.strategy.load_model_from(os.path.join(work_dirs, 'epoch_based_trainer', 'checkpoints', 'epoch_2', 'model.pth'))\n",
    "    runner.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dry Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "todd.Store.DRY_RUN = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "todd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fe19504897982c0d86de0bd38ea30a541b47032e25039ac5ae6cd1de5b1a414"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
